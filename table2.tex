% Table 2
\begin{table*}[!h]
\centering
\footnotesize
\caption{\textbf{Evaluation of  trained classifiers on the CSU and PP data}}
\begin{tabular}{c | c | c c | c c | c c }
\toprule
Model & \multicolumn{1}{c|}{EM} & \multicolumn{2}{c|}{Precision} & \multicolumn{2}{c|}{Recall} & \multicolumn{2}{c}{$F_1$} \\
& & unwgt & wgt & unwgt & wgt & unwgt & wgt \\
\midrule
& \multicolumn{7}{c}{CSU data} \\
\midrule
MetaMap - SVM & 32.2 & 52.2 & 74.8 & 54.8 & 75.0 & 53.2 & 74.8 \\
MetaMap - MLP & 41.2 & 64.7 & 82.6 & 48.5 & 71.8 & 55.0 & 76.4 \\
CNN & 45.1 & 73.1 & 84.4 & 57.2 & 78.4 & 62.2 & 80.9 \\
LSTM & 47.4 & 76.6 & 85.9 & 59.3 & 78.7 & 65.3 & 81.7 \\
BLSTM & 48.2 & 76.1 & 86.0 & 57.6 & 79.4 & 63.5 & 82.2 \\ 
DeepTag-M & \textbf{48.6} & 76.8 & \textbf{86.3} & 58.7 & 79.6 & 64.6 & 82.4 \\
\textbf{DeepTag} & 48.4 & \textbf{79.9} & 86.1 & \textbf{62.1} & \textbf{79.8} & \textbf{68.0} & \textbf{82.4} \\ 
\midrule
\midrule
& \multicolumn{7}{c}{PP data} \\
\midrule
MetaMap - SVM & 3.2 & 26.5 & 57.3 & 37.7 & 53.1 & 24.8 & 51.6 \\
MetaMap - MLP & 13.8 & 30.6 & 56.4 & 24.9 & 47.7 & 26.2 & 50.5 \\
CNN & 13.5 & 52.8 & 68.5 & 31.8 & 54.0 & 34.8 & 56.0 \\
LSTM & 13.8 & 48.1 & 65.7 & 31.8 & 51.9 & 33.8 & 54.4 \\ 
BLSTM & 13.8 & 47.3 & 66.0 & 35.6 & 57.9 & 36.9 & 58.4 \\ 
DeepTag-M & 17.1 & 53.4 & 68.0 & 37.9 & 59.9 & 40.6 & 61.1 \\ 
\textbf{DeepTag} & \textbf{17.4} & \textbf{56.5} & \textbf{70.3} & \textbf{41.4} & \textbf{62.4} & \textbf{43.2} & \textbf{63.4} \\ 
\bottomrule
\end{tabular}
\begin{flushleft}
Aggregate prediction performance across the 42 disease codes. 
We trained a multi-layer perceptron (MetaMap-MLP) algorithm and support vector machines (MetaMap-SVM) algorithm on discrete features generated by the MetaMap, which processes a document and extracts medically-relevant terms~\cite{aronson2010overview}.
CNN refers to a text convolution neural network implementation from Kim~\cite{kim2014convolutional}. BLSTM refers to the multi-task bidirectional LSTM. DeepTag is our best model, and DeepTag-M is the variation with a meta-disease loss. EM indicates the exact match ratio, which is the percentage of the clinical notes where the algorithm perfectly predicts all of the disease codes. For example, if a note has three true disease codes, then the algorithm achieves an exact match if it predicts exactly these three disease codes, no more and no less. For each precision, recall and $F_1$ score, there are two ways to compute an algorithm's performance. First we can take an unweighted average of the score across all the disease codes (unwgt) or we can take an average weighted by the number of test examples in each disease code (wgt). All the algorithms are trained on CSU and tested on a held-out CSU data and the PP data. 
\end{flushleft}
 \label{tab:pp}
\end{table*}